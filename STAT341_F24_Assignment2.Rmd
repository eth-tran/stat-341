---
title: "STAT 341: Assignment 2"
subtitle: "DUE: Tuesday November 5, 2024 by 5:00pm ET"
output:
  pdf_document: default
urlcolor: blue
header-include:
  - \usepackage{amsmath}
---
```{r setup, include = FALSE}
library(knitr)
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  tidy = "styler"
)
```

$\;$
$\;$
$\;$
$\;$

## NOTES

Your assignment must be submitted by the due date listed at the top of this document, and it must be submitted electronically in .pdf format via Crowdmark. This means that your responses for different questions should begin on separate pages of your .pdf file. Note that your .pdf solution file must have been generated by R Markdown. Additionally:

* For mathematical questions: your solutions must be produced by LaTeX (from within R Markdown). Neither screenshots nor scanned/photographed handwritten solutions will be accepted -- these will receive zero points.

* For computational questions: R code should always be included in your solution (via code chunks in R Markdown). If code is required and you provide none, you will receive zero points.
   + **Exception:** any functions defined in the lecture notes can be loaded using `echo=FALSE` but any other code chunks should have `echo=TRUE`. e.g., the code chunk loading `gradientDescent()` can use `echo=FALSE` but chunks that call `gradientDescent()` should have `echo=TRUE`.
   
* For interpretation questions: plain text (within R Markdown) is required. Text responses embedded as comments within code chunks will not be accepted.

Organization and comprehensibility is part of a full solution. Consequently, points will be deducted for solutions that are not organized and incomprehensible. Furthermore, if you submit your assignment to Crowdmark, but you do so incorrectly in any way (e.g., you upload your Question 2 solution in the Question 1 box), you will receive a 5% deduction (i.e., 5% of the assignment’s point total will be deducted from your point total).

\newpage

## QUESTION 1: Coding Best Practices [2 points]

This isn't so much an independent question as much as it's a motivator to use good coding practices when creating your solutions to this assignment. Read the **new** "Programming Guidelines" in Appendix A at the end of this document and do your best to adhere to these guidelines when preparing your solutions. You will be graded as follows:

* 2 points: good effort was taken to follow the stated programming guidelines
* 1 point: some effort was taken to follow the stated programming guidelines
* 0 points: no effort was taken to follow the stated programming guidelines

\newpage


## QUESTION 2: The Beale Function [36 points]

The Beale Function is one of many [test functions](https://en.wikipedia.org/wiki/Test_functions_for_optimization) used for evaluating the performance of optimization methods. For $\boldsymbol\theta = (\theta_1,\theta_2)^T \in \mathbb{R}^2$ the function is defined as follows $$\rho(\boldsymbol{\theta}) = \left(1.5-\theta_1+\theta_1\theta_2\right)^2 + \left(2.25-\theta_1+\theta_1\theta_2^2\right)^2 + \left(2.625-\theta_1+\theta_1\theta_2^3\right)^2.$$ The figure below depicts the function as a 3-dimensional surface for $\theta_1 \in [-5,5]$ and $\theta_2 \in [-5,5]$.

```{r, echo=FALSE, fig.align='center', fig.width=8, fig.height=5}
rho <- function(theta1, theta2) {
  (1.5-theta1+theta1*theta2)^2 + (2.25 - theta1 + theta1*theta2^2)^2 + (2.625 - theta1 + theta1*theta2^3)^2
}
theta1 <- seq(-5,5,length=100)
theta2 <- seq(-5,5,length=100)
Rho <- outer(theta1,theta2,"rho")
persp(
  x = theta1, y = theta2, z = Rho,
  theta = 300, phi = 15, expand = 0.5,
  xlab = "theta1", ylab = "theta2", zlab = "rho",
  ticktype = "detailed", cex.axis = 0.7, tck = 0.7
)
```

Although not clear from this visualization, the surface has a global minimum at $\rho(3,0.5)=0$.

(a) [2 points] By taking appropriate derivatives, determine the $2 \times 1$ gradient vector $\boldsymbol{g} =  \nabla\rho(\boldsymbol{\theta})$. Show your work.

(b) [4 points] Write functions `beale_rho()`^[In this question, you are asked to write several functions using `snake_case`, even though `gradientDescent()` is written in `camelCase`.  The rationale here is that the functions you are writing are for your own project -- this assignment -- rather than for the general codebase to which `gradientDescent()` belongs -- the entire collection of code for this course.  That being said, the rationale of writing assignment functions that use the same style as the course's codebase -- i.e., `camelCase` for both -- is equally valid.  So this is an example of the type of subjective judgement you need to make when choosing a naming style.] and `beale_gradient()` for the Beale Function which take a single vector-valued input `theta`. Use the partial derivatives calculated in part (a) in your definition of `beale_gradient()`.

(c) [4 points] In this question you will explore the surface of the Beale Function using gradient descent. In particular, you will consider 4 different starting values and explore the impact of changing one's starting location. Using the `gradientDescent()` function (from class) together with the `gridLineSearch()` and `testConvergence()` functions (from class) as well as the `beale_rho()` and `beale_gradient()` functions from part (b), find the solution to $$\operatorname*{arg min}_{\boldsymbol\theta \in \mathbb{R}^2} \rho(\boldsymbol\theta)$$ for each of the following four starting values. In each case, be sure to include the output from the `gradientDescent()` function. You will also find it helpful to set `maxIterations = 500` and `lambdaStepsize = 1e-03`.

      i. $\widehat{\boldsymbol{\theta}}_0=(3,3)^T$

      ii. $\widehat{\boldsymbol{\theta}}_0=(3,-3)^T$

      iii. $\widehat{\boldsymbol{\theta}}_0=(-3,-3)^T$

      iv. $\widehat{\boldsymbol{\theta}}_0=(-3,3)^T$

(d) [5 points] Construct a contour plot of the Beale Function over the domain $\theta_1 \in [-5,5]$ and $\theta_2 \in [-5,5]$. Specifically visualize the $\{10^0, 10^1, 10^2. 10^3, 10^4, 10^5\}$ level curves and colour them `darkgrey`. Include on this plot the four convergence paths corresponding to your findings from part (c). In particular:

    * Use line `segments()` to connect each starting point with the point of convergence. Note you will need to modify the `gradientDescent()` function from class to save (and return) the iterates.
    * Each of these paths should be a different colour starting at a (same-coloured) circle and ending at a (same-coloured) diamond.
    * After adding these lines, overlay a `black` diamond at the global minimum. 
    * Ensure your plot is informatively labeled and titled.

(e) [2 points] Based on what you found in part (c), and visualized in part (d), explain the importance of the starting value when performing non-convex optimization (when locating a global optimum is desired).

(f) [8 points] Determine $\psi(\boldsymbol\theta)$ and $\psi'(\boldsymbol\theta)$ for the Beale Function needed to solve $\psi(\boldsymbol\theta)=\mathbf{0}$. Write the corresponding `beale_psi()` and `beale_psi_prime()` functions for use with `NewtonRaphson()`.

(g) [4 points] In this question you will explore the surface of the Beale Function using the Newton-Raphson method and consider the same 4 starting values from part (c). Using the `NewtonRaphson()` function (from class) together with the `testConvergence()` function (from class) as well as the `beale_psi()` and `beale_psi_prime()` functions from part (f), find the solution to $\psi(\boldsymbol\theta)=\mathbf{0}$ for each of the following four starting values. In each case, be sure to include the output from the `NewtonRaphson()` function. For this question, you may use all of the default settings for `NewtonRaphson()` and `testConvergence()`.

      i. $\widehat{\boldsymbol{\theta}}_0=(3,3)^T$

      ii. $\widehat{\boldsymbol{\theta}}_0=(3,-3)^T$

      iii. $\widehat{\boldsymbol{\theta}}_0=(-3,-3)^T$

      iv. $\widehat{\boldsymbol{\theta}}_0=(-3,3)^T$
      
(h) [5 points] Repeat part (d) but this time based on your Newton-Raphson solutions from part (g).

(g) [2 points] Comment on the performance of the Newton-Raphson algorithm here. In particular:

    * Did it do what it was supposed to?
    * Explain why it didn't work as well as gradient descent did, and what it's doing differently.


\newpage

## QUESTION 3: Stochastic Gradient Descent [15 points]

In class we've explored *gradient descent* as an iterative method for finding $$\hat{\boldsymbol{\theta}}=\operatorname*{argmin}_{\boldsymbol{\theta}\in\Theta}\rho(\boldsymbol{\theta};\mathcal{P}).$$ We've also noted that our objective functions tend to have the form $$\rho(\boldsymbol{\theta};\mathcal{P})=\sum_{u\in\mathcal{P}}\rho(\boldsymbol\theta;u),$$ in which each unit $u\in\mathcal{P}$ contributes a component $\rho(\boldsymbol\theta;u)$ to the objective. Consequently, each unit contributes a component $\nabla\rho(\boldsymbol\theta;u)$ to the corresponding gradient: $$\boldsymbol{g}=\nabla\rho(\boldsymbol{\theta};\mathcal{P}) = \sum_{u\in\mathcal{P}}\nabla\rho(\boldsymbol\theta;u).$$

Until now we've assumed that the gradient $\boldsymbol{g}_i$ calculated at iteration $i$ is based on all of the available data, i.e., all of the units $u\in\mathcal{P}$. However, if the population $\mathcal{P}$ is very large, or if the unit-specific gradient contributions $\nabla\rho(\boldsymbol\theta;u)$ are expensive to calculate, we could consider using just a *subset* of the units instead of all of them. Denote such a subset by $\mathcal{S}\subset\mathcal{P}$. The gradient calculated only over the units $u\in\mathcal{S}$ would *approximate* the gradient calculated with all of the data. That is, $$\hat{\boldsymbol{g}} = \sum_{u\in\mathcal{S}}\nabla\rho(\boldsymbol\theta;u)$$ is an approximation of $$\boldsymbol{g} = \sum_{u\in\mathcal{P}}\nabla\rho(\boldsymbol\theta;u).$$ When the subset $\mathcal{S}$ is taken to be a simple random sample, this method is referred to as *stochastic gradient descent* (SGD). 

Relative to ordinary gradient descent (OGD), SGD can dramatically improve computational efficiency: by using just a subset of the data at each iteration, the gradient calculations and hence iterations themselves are made faster. Basing the calculations on sample $\mathcal{S}$ instead of the entire population $\mathcal{P}$ also has the benefit of reducing the memory required to perform the calculations.

However, the use of approximate gradients comes at a cost; while SGD iterations are quicker than OGD ones, more iterations are typically required for convergence. In fact, the manner in which SGD convergence is assessed is altered. Because the gradient at iteration $i$ is approximate, the direction it points ($-\hat{\boldsymbol{d}}_i$) may not be along the path of steepest descent ($-\boldsymbol{d}_i$). As such, we typically do not determine the step size $\lambda_i$ with a line search in a potentially sub-optimal direction. Instead, it is typical to define a step size using what is known as a *decaying learning rate*. One such example is $$\lambda_i = \frac{0.1}{1+0.1\times i}.$$  The updating equation may then be written as $$\hat{\boldsymbol{\theta}}_{i+1}=\hat{\boldsymbol{\theta}}_{i}-\lambda_i\hat{\boldsymbol{d}}_i$$ and convergence is evaluated not by assessing the size of $\left\Vert\hat{\boldsymbol{\theta}}_{i+1}-\hat{\boldsymbol{\theta}}_{i}\right\Vert$, it's instead evaluated by running the algorithm for many iterations and using *trace plots* (i.e., plots of $\hat{\boldsymbol{\theta}}_{i}$ versus $i$) to identify stability. 

In this question, you will write new functions and modify existing ones to perform SGD in the context of simple least squares regression, and in so doing build confidence in this stochastic approximation to gradient descent.

(a) [5 points] While we could write a new function in R to perform stochastic gradient descent, we already have the general-purpose implementation of `gradientDescent()`. Sometimes it's more efficient to make use of functionality already available than it is to develop something brand new. We'll emphasize this principle by implementing SGD without completely overhauling `gradientDescent()` and instead just modifying how we use it. 
    
    i. [1 point] `gradientDescent()` requires a function to be passed into `rhoFn`, yet SGD will not require this. Write a function called `dummy_objective()` that takes in a vector `theta` and that simply returns `NULL`.
    
    ii. [1 point] `gradientDescent()` requires a function to be passed into `testConvergenceFn`, yet SGD will not require this. Write a function called `dummy_convergence_test()` that has the same arguments as `testConvergence()` from class but that simply returns `FALSE`.
    
    iii. [1 point] `gradientDescent()` requires a function to be passed into `lineSearchFn`, yet SGD does not perform a line search to determine the step size $\lambda_i$. However, through this argument we can force `gradientDescent()` to calculate $\lambda_i$ using a decaying learning rate as described above. Write a function called `decay_learning_rate()` that has the same arguments as `gridLineSearch()` from class but with an additional argument called `iteration`. This function should return $0.1/(1+0.1\times i)$ on `iteration` $i$. Note that you will also have to update the call to `lineSearchFn()` in `gradientDescent()` to include the argument `iteration`.
	
         **Note:** Modify the version of `gradientDescent()` from Question 2(d) -- the one that returns the iterates -- not the one from the course notes, in anticipation of Questions 3(b)-(d).
    
    iv. [2 points] `gradientDescent()` requires a function to be passed into `gradientFn`. You will find that the `createLeastSquaresGradient()` factory function from class is no longer useful here, since it produces a gradient function that encapsulates the *entire* population (which is not necessary for SGD). Create a new factory function `create_least_squares_stochastic_gradient()` which takes in the data `x` and `y`, as well as a sample size `n`. This function should then return the least squares gradient function, calculated on a random `sample()` of `n` units.

(b) [4 points] In this question you will use SGD to calculate $\hat\alpha$ and $\hat\beta$, the intercept and slope of the least squares line-of-best-fit for the data found in `waldo.csv`. Do so using `gradientDescent()` (the version from Question 2(d) that returns the iterates) together with the functions you wrote in part (a). Additionally, start the optimization at $\hat{\boldsymbol{\theta}}_0=(1,1)$, set `maxIterations=5000`, and use samples of size $n=20$. Construct two trace plots as follows:

    * Plot a line of $\hat\alpha_i$ vs. $i$ and overlay a horizontal line at the true (population) value of $\hat\alpha$.
    * Plot a line of $\hat\beta_i$ vs. $i$ and overlay a horizontal line at the true (population) value of $\hat\beta$.
    * Ensure the two plots are titled and labelled informatively, and arranged in a $2\times 1$ layout.

(c) [4 points] Repeat part (b) but with samples of size $n=5$ and start the optimization at  $\hat{\boldsymbol{\theta}}_0=(10,10)$.

(d) [2 points] Based on the trace plots in parts (b) and (c), what do you conclude about SGD's ability to converge despite using stochastic approximations to the gradient?



\newpage 

## QUESTION 4: Polynomial Regression with IRLS [23 points]

Suppose we have a population $\mathcal{P}$ of $N$ units on which we observe the following pairs of variates $\{(x_1,y_1),\ldots,(x_N,y_N)\}$. In class we've considered summarizing the *linear* relationship between $y$ and $x$ where we have (by a variety of methods) calculated the line-of-best-fit. Here we will extend this idea to a curve-of-best-fit which may be used to describe a possible *non-linear* relationship between $y$ and $x$. We do so with the following *polynomial regression* model: $$y_u=\beta_0+\beta_1x_u+\beta_2x_u^2+\cdots+\beta_px_u^p+r_u$$ for all $u\in\mathcal{P}$. The curve-of-best-fit is defined as $$\hat{y}=\hat\beta_0+\hat\beta_1x+\hat\beta_2x^2\cdots+\hat\beta_px^p$$ where we will estimate the coefficients by minimizing the sum of absolute deviations: $$\boldsymbol{\hat\theta}=(\hat\beta_0,\hat\beta_1,\hat\beta_2,\ldots,\hat\beta_p)=\operatorname*{argmin}_{\boldsymbol{\theta}\in\mathbb{R}^{p+1}}\sum_{u\in\mathcal{P}}\left|y_u-\beta_0-\beta_1x_u-\beta_2x_u^2-\cdots-\beta_px_u^p\right|.$$

Although this is a non-linear function of the $x$'s, it is a linear function of the $\beta$'s and hence a candidate for iteratively reweighted least squares. In this question you will fit such polynomial regressions (of arbitrary degree $p$) using IRLS.

(a) [2 points] The IRLS algorithm (and consequently the `irls()` function) defines weights as $w_u = \rho^\prime(r_u)/r_u$. Derive $\rho^\prime(r_u)$ in this context and write a corresponding `lad_rho_prime()` function for use with `irls()`.

(b) [2 points] The `getResids()` function from class will not be appropriate here as it was written specifically for a simple linear regression. Write a new `getResids()` function which returns a vector of residuals $r_u=y_u-\beta_0-\beta_1x_u-\beta_2x_u^2-\cdots-\beta_px_u^p$, $\forall ~ u\in\mathcal{P}$, having taken in the following arguments:

    * `x`: an $N$-element vector of explanatory variate values.
    * `y`: an $N$-element vector of response variate values.
    * `wt`: an $N$-element vector of unit-specific weights.
    * `theta`: a $(p+1)$-element vector corresponding to $(\beta_0,\beta_1,\beta_2,\ldots,\beta_p)$.

(c) [3 points] Available in `kw_temperature.csv` are daily average temperatures (in °C) recorded in Kitchener-Waterloo from January 2020 to October 2024 [recorded by Environment Canada](https://climate.weather.gc.ca/climate_data/daily_data_e.html?StationID=48569). These temperatures, plotted by day of the year, display a decidedly non-linear trend. Construct a scatterplot of these data treating `y = Mean_Temp` as the dependent variable and `x = Day_of_Year/365` as the independent variable. This plot displays daily average temperature as a function of the proportion of the year elapsed. Note that `y = Mean_Temp` includes a number of `NA` values which should be removed prior to analysis. Make sure your plot is informatively titled and labelled.

(d) [3 points] Using the `irls()` function from class, calculate and state the equations of the LAD-based curves-of-best-fit for $p\in\{2,3,4,5\}$. Note that you may also use the `getWeights()` and `testConvergence()` functions from class as well as the `getTheta()` provided in Appendix B at the end of this document. Note that you will have to update the call to `getTheta()` in `irls()` to include the argument `p`.

(e) [4 points] Recreate the scatter plot from part (c) and overlay the four curves of best fit. Use different colours and/or line types for these curves, and include a legend to distinguish them. Be sure to include an informative title and axis labels on your plot.

(f) [6 points] In this part you will investigate sample error, and sampling variability in the context of regression. To do so, complete the following tasks for $n\in\{50,100,500\}$. 

    * Take 100 simple random samples of size $n$ from the population $\mathcal{P}$.
    * Use `irls()` to calculate the quintics-of-best-fit (i.e., $p=5$) for each of these samples.
    * Construct a plot of the 100 quintics-of-best-fit, each overlayed on top of one another and coloured with `adjustcolor("black", 0.3)`. 
    * On top of these 100 sample curves, add (in `col=red` and with `lwd=2`) the population quintic-of-best-fit from part (d).
    * Include a legend and label the plot appropriately.
    
    Organize these three plots side-by-side in a $1 \times 3$ layout.

(g) [3 points] Based on your visualization in part (f), comment on sample error, sampling variability, and these concepts as a function of $n$, in the context of this polynomial regression.

\newpage

## APPENDIX A: Programming Guidelines

#### Motivation

In Assignment 1, we made the case that **good documentation** was perhaps the most fundamental component of writing good computer code, i.e, which is both *clear* and *simple*.  We started by outlining three key elements of best documentation practices:

1.  **Comment your code extensively.**  

2.  **Use informative variable names.**

3.  **Call functions using key-value pairs.**


In Assignment 2, you are asked to write several relatively complex functions, some of which are generally useful outside the scope of the assigment itself.  Since such functions are typically the building blocks of larger computing projects, software libraries, etc., it is especially important to document them as clearly and extensively as possible.  In fact, documenting functions is so important that it deserves a new key element of documentation best practices:


4.  **Document your functions in a standardized way.**  

Almost every programming language has its own standard.  In R, this is achieved using `roxygen`-style comments.  `roxygen` is not only a specifc function documentation format, it is also an R package which automatically converts that format into the help files that come with other R packages, e.g., when you type `?mean`.   Prior to `roxygen`, it was unbelievably tedious to write R package documentation that when `roxygen` came out, it caught on like wildfire, quickly becoming the industry standard.  

Thus, while technically you are free to document functions any way you want, using `roxygen` will not only be familiar to R users at large, it will also save you a ton of time when you want to wrap your functions into an R package, which is extremely useful for managing larger projects, distributing code, etc.  So using **roxygen** is an example of a programming two-for-one (or "twofer") -- try to use these whenever you find them and watch your programming productivity multiply.

#### `roxygen` Documentation

The elements of `roxygen` style are extensively documented on the package [website](https://roxygen2.r-lib.org/), and there is a nice, brief introduction to it [here](https://r-pkgs.org/man.html).  There are also several examples of it on LEARN in the solutions to Assignment 1, and in Section 2.3.2a of the "Additional R Code" document in the *(OPTIONAL) Supplementary Material* section.  We also have an example in the definition of `getTheta()` in Appendix B, which we use to summarize the key elements of the `roxygen` style:

- `roxygen` documentation is placed right above the function definition, with each line starting with a `#'`.

- The first line of the `roxygen` documentation is the "title" of the function, i.e., a short sentence explaining what it does.

- Each argument of the function is documented using the `@param` tag.  Typically one specifies the type of the argument (e.g., string, number, numeric vector, etc.), in addition to what the argument represents.

- The output of the function is documented using the `@return` tag.

- A `@details` section can be included for any additional explanations.

- Use Markdown syntax within the documentation.  In particular:

	- Markdown lists are great for documenting arguments (`@param`) or output (`@return`) which are, well, lists.
	
	- The use of backticks is particularly helpful for clear and simple formatting of math and code expressions.  See examples in the documentation for `getTheta()`.  
	
	- A more advanced type of Markdown formatting is to use [function links](https://roxygen2.r-lib.org/articles/rd-formatting.html#function-links) for referring to your own functions or functions in other R packages.
	
- Try to cap lines at 80 characters or less.  When a given `roxygen` block (e.g., `@param`, `@return`, etc.) runs for more than one line, it's customary (but not required) to indent all subsequent lines by an extra two spaces.

#### Caveat

Deciding when to use various `roxygen` blocks (if any) is sometimes a bit subjective.  For example:

- Sometimes a full-blown `@details` section is a bit overkill.

- Some very simple functions -- one or two arguments, auxiliary functions such as `rho()` and `grad()` -- don't need documentation.

#### Grading

For Assignment 2, you will be graded on **all four elements** of best documentation practices described above, i.e., including the first three elements introduced in Assignment 1.  You are expected to use `roxygen` documentation for *at minimum* the following Assignment 2 functions:

- `create_least_squares_stochastic_gradient()` in Question 3(a).

- `getResids()` in Question 4(b).

You are also expected to use it for any custom functions you introduce of similar complexity and/or generalizability. 

\newpage

## APPENDIX B: `getTheta()`

```{r getTheta}
#' Compute the weighted least-squares estimate of a polynomial-of-best-fit.
#'
#' @param y A numeric response vector of length `N`.
#' @param x A numeric covariate vector of length `N`.
#' @param wt A vector of nonnegative weights of length `N`.
#' @param p An integer specifying the degree of the polynomial to fit.
#'   See Details.
#'
#' @return A vector of length `p+1` specifying the coefficients of the
#'   polynomial-of-best-fit.  See Details.
#'
#' @details Let
#'   ```
#'   poly_p(x, theta) = theta[1] + theta[2] * x + theta[3] * x^2
#'                      + ...
#'                      + theta[p+1] * x^p.
#'   ```
#'   denote a p-degree polynomial in `x`.  Then the polynomial-of-best-fit is
#'   that for which `theta` is the solution to the minimization problem
#'   ```
#'   theta_hat = argmin_theta sum( wt * (y - poly_p(x, theta))^2 ).
#'   ```
#'   This has a closed-form solution which is discussed in STAT 331.  That is,
#'   let `X` denote the `N x (p+1)` matrix with columns `X[,i] = x^(i-1)`.  So
#'   `X[,1]` is a column of ones, `X[,2] = x`, etc.  Let `W = diag(wt)`, i.e., a
#'   diagonal matrix with the elements of `wt` on the diagonal.  Then the
#'   solution to the minimization problem above is
#'   ```
#'   theta_hat = (X^T W X)^{-1} (X^T W y).
#'   ```
#'   This can be computed very efficiently using [stats::lm.wfit()], the low-
#'   level function underlying the [stats::lm()] function in R.
getTheta <- function(y, x, wt, p) {
  # construct matrix X = [1, x, x^2, ..., x^p]
  N <- length(x)
  X <- matrix(1, nrow = N, ncol = p+1)
  for(i in 1:p) {
    X[, i+1] <- X[,i] * x
  }
  # compute WLS solution
  fit <- stats::lm.wfit(x = X, y = y, w = wt)
  # return fitted coefficients with names removed
  setNames(fit$coefficients, NULL) 
}
```
